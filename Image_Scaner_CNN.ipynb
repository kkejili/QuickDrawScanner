{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image_Scaner_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from urllib.request import urlretrieve\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import PIL.ImageOps\n",
    "import os\n",
    "from os.path import isfile, isdir\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取下载文件保存路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_full_name(folder_path, name):\n",
    "    return folder_path + name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下载文件到指定文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "        \n",
    "def download_files(folder_path, image_names):\n",
    "    if not isdir(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "    for image_name in image_names:\n",
    "        if not isfile(get_file_full_name(folder_path, image_name)):\n",
    "            # 谷歌云存储公共下载链接\n",
    "            url = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/' + image_name + '.npy'\n",
    "            # base64 转换之空格版\n",
    "            url = url.replace(' ', '%20')\n",
    "            with DLProgress(unit='B', unit_scale=True, miniters=1, desc=image_name) as pbar:\n",
    "                urlretrieve(\n",
    "                url,\n",
    "                folder_path + image_name,\n",
    "                pbar.hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取最大的文件大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_images_size(folder_path, image_names):\n",
    "    image_num_list = []\n",
    "    for image_name in image_names:\n",
    "        images = np.load(get_file_full_name(folder_path, image_name))\n",
    "        image_num_list.append(len(images))\n",
    "    return max(image_num_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取数组乱序列表（numpy）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shuffle(data):\n",
    "    records = len(data)\n",
    "    shuffle = np.arange(records)\n",
    "    np.random.shuffle(shuffle)\n",
    "    return shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 序列化数据到指定路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save_data(folder_path, features, labels):\n",
    "    pickle.dump((features, labels), open(folder_path, 'wb'))\n",
    "#     train_features, valid_features, train_labels, valid_labels = train_test_split(features, labels, test_size = 0.1)\n",
    "#     pickle.dump((train_features, train_labels), open(folder_path + '/train', 'wb'))\n",
    "#     pickle.dump((valid_features, valid_labels), open(folder_path + '/valid', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return x / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2index(image_names):\n",
    "    result = {}\n",
    "    for index, name in enumerate(image_names):\n",
    "        result[name] = index\n",
    "    return result\n",
    "def one_hot_encode_lb(x):\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb.fit(range(len(x)))\n",
    "    return lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name_file = 'mini_quick_draw.txt'\n",
    "batch_num = 0\n",
    "batch_max = 700\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "star: 108MB [00:01, 55.7MB/s]                              \n",
      "square: 98.1MB [00:01, 73.6MB/s]                              \n",
      "face: 127MB [00:01, 68.6MB/s]                              \n",
      "moon: 95.4MB [00:01, 72.4MB/s]                            \n",
      "butterfly: 92.5MB [00:01, 80.0MB/s]                            \n",
      "cell phone: 95.0MB [00:01, 69.5MB/s]                            \n",
      "cup: 102MB [00:01, 70.0MB/s]                              \n",
      "pants: 113MB [00:01, 76.8MB/s]                              \n",
      "clock: 94.5MB [00:01, 72.1MB/s]                            \n",
      "triangle: 96.6MB [00:01, 76.9MB/s]                            \n",
      "basketball: 105MB [00:01, 78.1MB/s]                              \n",
      "lollipop: 101MB [00:01, 69.8MB/s]                            \n",
      "rainbow: 99.5MB [00:01, 78.2MB/s]                              \n",
      "fish: 105MB [00:01, 53.2MB/s]                              \n",
      "fork: 98.8MB [00:01, 76.1MB/s]                            \n"
     ]
    }
   ],
   "source": [
    "image_names = []\n",
    "with open(image_name_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        if lines:\n",
    "            image_names.append(line.replace('\\n',''))\n",
    "\n",
    "folder_path = 'npys/'\n",
    "download_files(folder_path, image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 显示下载数据（可选）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvUlEQVR4nJ3ST0iTcRzH8fezP200\niB6NtFJGMXxyiSQRZBgUMRKiiJrHPNWhW3YbQR0C8WDQIUZlBR46TAqDPEizIAYetMWyQHexzIPR\nQVCQWc+e59NhY5ugBn1P3x8vvvDj8/0aYuvybGPbow+ATN887Ii0Woc762vQEDDf4cQsCvn8gvzd\nVy8EKyrpT0vjZ0mS1rJ3DrH75s/SS0h6RlqVcjPXAqHbhQpaXdLjM7ExSdJMeiTZ44nOljHHsPLe\nFqNN0vuzAE3jzU0/SnjXv6wJjsOiUoQffpwdJjNXf9SRPDDRZdJ5cBps8sTje2ccGqwnubeAijsT\nkqYutyakNAAhy1YxfFFCOV5V/zq4C2j/Iume97vQcxaqqML4yw+2JC2SlI8V9tQkFjxXbur4/a+t\nBFjeDAR4OO97uhm+IQpSvGFd9qNVbSjnyDFXSJNGr7sUPP2r1oo3eF0KfpA+Z9QfuPSiOt1PxJUM\nAYmBE/cbh1LffAeaw/u84L77xEhPadnS6H46htam+693R+tM0wyFjFuOypOwnkpO+dvazQA4XydX\now9ilRsCIDuWnVuxgcjJK6dqDmzrhP4X/wIoZyGCBryiqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7F33183AEFD0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_name = 'face'\n",
    "images = np.load(folder_path + image_name)\n",
    "PIL.ImageOps.invert(Image.fromarray(images[0].reshape(28,28)).resize((28,28),Image.ANTIALIAS).convert('L'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_images_size = get_max_images_size(folder_path, image_names)\n",
    "w2i = word2index(image_names)\n",
    "lb = one_hot_encode_lb(image_names)\n",
    "\n",
    "if not isdir('data'):\n",
    "        os.mkdir('data')\n",
    "\n",
    "for start in range(0, max_images_size, batch_size):\n",
    "    if batch_num > batch_max:\n",
    "        break\n",
    "    features = []\n",
    "    labels = []\n",
    "    for image_name in image_names:\n",
    "        images = np.load(folder_path + image_name)\n",
    "        end = min(start + batch_size, len(images))\n",
    "        if start < end:\n",
    "            for feature in images[start:end]:\n",
    "                feature = Image.fromarray(feature.reshape(28,28))\n",
    "                feature = feature.resize((28,28),Image.ANTIALIAS)\n",
    "                feature = feature.convert('L')\n",
    "                feature = np.array(feature).astype(np.float32)\n",
    "                features.append(feature.reshape(28, 28, 1))\n",
    "                labels.append(w2i[image_name])\n",
    "    if labels:\n",
    "        shuffle = get_shuffle(labels)\n",
    "        features = np.array(features)\n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # 打乱\n",
    "        features = features[shuffle]\n",
    "        labels = labels[shuffle]\n",
    "        \n",
    "        features = normalize(features)\n",
    "        labels = lb.transform(labels)\n",
    "        # 保存\n",
    "        preprocess_and_save_data('data/batch' + str(batch_num), features, labels)\n",
    "        batch_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试数据预处理是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1500 条\n",
      "(1500, 15)\n",
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f335b6f3a20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAWJQAAFiUBSVIk8AAAHiNJREFUeJzt3Xu0ZGV5J+DfS6MgrYASlfG2AAPqeA0QMTBBLhEhJgQj\nRGeWyrg0UaOjKE6cSTRpL7OWfyQKYtRMMCEjmUEHV0wc8TJREBQ1oRUZIooEEFEQARsQBOzmmz+q\nOnbac/pSu/rUOV89z1q19qm9663v7e2W3/lO7dq7WmsBAPq006wbAAB2HEEPAB0T9ADQMUEPAB0T\n9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB3bedYN\n7AhVdU2S3ZNcO+NWAGBS+yS5vbW275A36TLok+y+U1Y9ZHUe9JBZNwIAk7gzd+S+bBj8PjMN+qp6\nVJK3Jjk2yV5Jbkjy0SRvaa39cMBbX7s6D3rIIfUrU+gSAJbel9vf546su3bo+8ws6KvqsUkuTvKw\nJH+b5BtJnp7ktUmOrarDWmu3zKo/AOjBLE/Ge29GIf+a1toJrbX/0lo7Ksm7kjwuyX+bYW8A0IWZ\nBP14Nn9MRifL/elmm/8oyZ1JXlRVq5e4NQDoyqxm9EeOl59urd236YbW2h1JvpBktyTPWOrGAKAn\ns/qM/nHj5ZWLbP9WRjP+A5J8ZrE3qaq1i2x6/OStAUA/ZjWj32O8vG2R7RvX77kEvQBAt1b09+hb\nawcttH480z9widsBgGVnVjP6jTP2PRbZvnH9uiXoBQC6Naug/+Z4ecAi2/cfLxf7DB8A2AazCvrz\nx8tjqupf9VBVD0pyWJK7knxpqRsDgJ7MJOhba/+c5NMZXbD/VZttfkuS1Uk+2Fq7c4lbA4CuzPJk\nvN/N6BK4766qo5NckeSQjL5jf2WSP5hhbwDQhZldAnc8qz84yVkZBfypSR6b5PQkz3CdewAYbqZf\nr2utfSfJS2bZAwD0bEV/jx4YZtX++01ce8Oz9h409u7XrR9Uv+t5i10Yc+uuf+Mhg8YeYp9zvjuo\nfv01355SJ8yLWd69DgDYwQQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM\n0ANAxwQ9AHRM0ANAxwQ9AHTMbWphxu599sET1z56zZWDxv7AY/73xLX3q1WDxr7rvnsH1Z949H+Y\nuPbDL/+TQWM/8f4PmLj2/S965KCxP3bUkyauXX/j9weNzcpkRg8AHRP0ANAxQQ8AHRP0ANAxQQ8A\nHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHXM/ehjoxlMOHVR/\nwal/PHHtp+4adm/zJ/7Vqyeu3ffv7hw09qpbh9VvuPKqiWtfv88vDRr7nuf84sS1n/rv7x009p+8\n/viJa/f7Pfejn0dm9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T\n9ADQMUEPAB0T9ADQMUEPAB1zm1pI8r3fm/xWs5e+9j2Dxj72G8+fuPZ+z79r0Nj73vzFQfVDbJjZ\nyMPt8vF/nLj2d79z5KCxjzri0olrrx00MiuVGT0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0A\ndEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdMz96OnCzvs8ZlD9Ja89feLaIy//\nrUFj73b89yau3XDPPYPGZun93C4/GlT/lVsfPXHtTvnOoLFZmWY2o6+qa6uqLfK4cVZ9AUBPZj2j\nvy3JaQusH/YrLwCQZPZBv661tmbGPQBAt5yMBwAdm/WMfpeqemGSxyS5M8llSS5srW2YbVsA0IdZ\nB/3eST642bprquolrbXPba24qtYusunxgzsDgA7M8k/3f5nk6IzCfnWSJyf5syT7JPlEVT11dq0B\nQB9mNqNvrb1ls1WXJ3lFVf0oyalJ1iR57lbe46CF1o9n+gdOoU0AWNGW48l47x8vD59pFwDQgeUY\n9D8YL1fPtAsA6MByDPpnjJdXz7QLAOjATIK+qp5QVT8zY6+qfZK8Z/z07KXsCQB6NKuT8Z6f5NSq\nujDJt5PckeSxSZ6TZNck5yX54xn1BgDdmFXQn5/kcUl+IclhGX0evy7J5zP6Xv0HW2ttRr0BQDdm\nEvTji+Fs9YI4sK1uOO6Rg+p3qftNXLvrW3YfNHa755pB9aws/37PLw+q//BXDp649gC3qZ1Ly/Fk\nPABgSgQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANA\nxwQ9AHRM0ANAx2ZyP3qYth8+/d5B9Zfde/fEtfXFywaNzcqz6uf2mrj2abvsMmjsXb99/0H1zB8z\negDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDo\nmKAHgI65TS19+Mmw31lXpU1e3AbUsiLddch+A6o/M2jsPf75vkH1zB8zegDomKAHgI4JegDomKAH\ngI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomPvR04Vd\nv3e/QfVPvP8DJq6975d/YdDYO1301UH1LL27X/XDiWvX3nPvoLEf8vErJq7dMGhkViozegDomKAH\ngI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI65\nTS3Lxg2nHjpx7QNubIPG/siPdp+49j+e+XeDxv7r5xw+ce2Gq64ZNPa8uvGUyY+1JLnkqWdMXPuE\n//naQWM/dt0XB9Uzf6Yyo6+qE6vqjKq6qKpur6pWVWdvpebQqjqvqm6tqh9X1WVVdUpVrZpGTwDA\n9Gb0b0ry1CQ/SnJ9ksdv6cVV9RtJPpLk7iQfSnJrkl9P8q4khyU5aUp9AcBcm9Zn9K9LckCS3ZO8\ncksvrKrdk/x5kg1JjmitvbS19p+TPC3JF5OcWFUvmFJfADDXphL0rbXzW2vfaq1tywelJyZ5aJJz\nWmuXbPIed2f0l4FkK78sAADbZhZn3R81Xn5ygW0XJrkryaFVtcvStQQAfZpF0D9uvLxy8w2ttfVJ\nrsno3IH9lrIpAOjRLL5et8d4edsi2zeu33Nrb1RVaxfZtMWTAQFgXrhgDgB0bBYz+o0z9j0W2b5x\n/bqtvVFr7aCF1o9n+gduf2sA0JdZzOi/OV4esPmGqto5yb5J1ie5eimbAoAezSLoPzteHrvAtsOT\n7Jbk4tbaPUvXEgD0aRZBf26Sm5O8oKoO3riyqnZN8vbx0/fNoC8A6M5UPqOvqhOSnDB+uvd4+UtV\nddb455tba29Iktba7VX12xkF/gVVdU5Gl8A9PqOv3p2b0WVxAYCBpnUy3tOSnLzZuv3y0+/CfzvJ\nGzZuaK19tKqemeQPkjwvya5Jrkry+iTv3sYr7AEAWzGVoG+trUmyZjtrvpDkV6cxPgCwMPejZ9l4\n6HHXT1x78qMuHjT2+15+4sS1Z/3VuweN/avn//XEtYd8fthtIR583m4T167+/k8GjX3bvvcbVH/P\ns2+fuPZrh7xn0NjHfuOErb9oEfuvuWzQ2PcNqmYeuWAOAHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANA\nxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAx9ymlmVj3YcfOXHti9fcPGjsDzxw\n8v8r/M6zXzJo7CvesMfEtZ971mmDxn7MMx84qH6WvnT3holr9//Mbw8a+2Gfvv/EtXvc+Z1BY8P2\nMqMHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAH\ngI4JegDomKAHgI65Hz3LxsP+x1cnrl37X+8dNPZNL/7xxLWPOelbg8Y+4KWT175iz+cMGvsnT9p3\n4to7H7nroLFXf/fuQfU7feFrE9e2v6hBY5/21j+duPaPzj5o0NiwvczoAaBjgh4AOiboAaBjgh4A\nOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOuY2tSwb9909+W1L\nT/rcKweNfeFRp09c+zt7HT9o7A233Dp57brbBo290+cvnbj2QYNGnq03HvLJQfVvuPKkiWtX5+pB\nY8P2MqMHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDo\nmKAHgI4JegDomKAHgI65Hz1d2O+sNqj+Ucc8cOLa609+/KCx/807Lx5UP69W7b/fxLWv2PPSQWOf\ncfbeE9e6Hz1LbSoz+qo6sarOqKqLqur2qmpVdfYir91nvH2xxznT6AkAmN6M/k1JnprkR0muT7It\nU5yvJfnoAusvn1JPADD3phX0r8so4K9K8swk529DzaWttTVTGh8AWMBUgr619i/BXlXTeEsAYApm\neTLeI6rq5Un2SnJLki+21i6bYT8A0J1ZBv2zxo9/UVUXJDm5tXbdtrxBVa1dZNOw06ABoBOz+B79\nXUneluSgJA8ePzZ+rn9Eks9U1eoZ9AUA3VnyGX1r7aYkf7jZ6gur6pgkn09ySJKXJTl9G97roIXW\nj2f6Bw5sFQBWvGVzZbzW2vokZ46fHj7LXgCgF8sm6Md+MF760z0ATMFyC/pnjJeuEQkAU7DkQV9V\nB1bVz4xbVUdndOGdJFnw8rkAwPaZysl4VXVCkhPGTzfe7eGXquqs8c83t9beMP75nUn2r6qLM7qa\nXpI8JclR45/f3Fpzlw8AmIJpnXX/tCQnb7Zuv/EjSb6dZGPQfzDJc5P8YpLjktwvyfeTfDjJe1pr\nF02pJwCYe9O6BO6aJGu28bUfSPKBaYwLAGyZ+9HThVUXfGVQ/dtvnvxiioc8/2uDxr7unYPK59Z3\nf23ye8IP9ehP3TZxbZtiH7AtlttZ9wDAFAl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiY\noAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiY29RCkr/+yFET117x8vcOGvvYg184cW275PJBY69o\nz/zhxKV/d+dug4Zua/9pUD0sJTN6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6\nAOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiY+9FDkv3OvHbi2h++7K5BY1958uqJa/e/ZNDQ\ns1U1qPz0J39o4tqXX/LCQWPvk8sG1cNSMqMHgI4JegDomKAHgI4JegDomKAHgI4JegDomKAHgI4J\negDomKAHgI4JegDomKAHgI4JegDomKAHgI4JegDomNvUQpL13/3exLW/9k/Dbnn63uPOmrj2tJ2f\nPGjstn79oPpBYx/61EH1RzzgqxPX7va5Bw4aG1YSM3oA6JigB4COCXoA6JigB4COCXoA6JigB4CO\nCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6Jj70cNAdeZDB9X/23feMnHt\nqr0fPmjs9dd/d1D9ENcds9ug+g3tvolrH/GJYf/u9YOqYWkNntFX1V5V9bKq+puquqqqflxVt1XV\n56vqpVW14BhVdWhVnVdVt45rLquqU6pq1dCeAICRaczoT0ryviQ3JDk/yXVJHp7kN5OcmeS4qjqp\ntdY2FlTVbyT5SJK7k3woya1Jfj3Ju5IcNn5PAGCgaQT9lUmOT/Lx1n76t7Sq+v0k/5DkeRmF/kfG\n63dP8udJNiQ5orV2yXj9m5N8NsmJVfWC1to5U+gNAOba4D/dt9Y+21r72KYhP15/Y5L3j58escmm\nE5M8NMk5G0N+/Pq7k7xp/PSVQ/sCAHb8Wfc/GS83PXflqPHykwu8/sIkdyU5tKp22ZGNAcA82GFn\n3VfVzklePH66aag/bry8cvOa1tr6qromyROT7Jfkiq2MsXaRTY/fvm4BoE87ckb/jiRPSnJea+1T\nm6zfY7y8bZG6jev33FGNAcC82CEz+qp6TZJTk3wjyYt2xBhJ0lo7aJHx1yY5cEeNCwArxdRn9FX1\n6iSnJ/l6kiNba7du9pKNM/Y9srCN69dNuzcAmDdTDfqqOiXJGUkuzyjkb1zgZd8cLw9YoH7nJPtm\ndPLe1dPsDQDm0dSCvqremNEFby7NKORvWuSlnx0vj11g2+FJdktycWvtnmn1BgDzaipBP77YzTuS\nrE1ydGvt5i28/NwkNyd5QVUdvMl77Jrk7eOn75tGXwAw7wafjFdVJyd5a0ZXursoyWuqavOXXdta\nOytJWmu3V9VvZxT4F1TVORldAvf4jL56d25Gl8UFAAaaxln3+46Xq5KcsshrPpfkrI1PWmsfrapn\nJvmDjC6Ru2uSq5K8Psm7N70uPgAwueoxU6tq7YOy54GH1K/MuhXYup0G3LDxvg3T62OJrTr/EYPq\nD91r8vN1L3rKroPGhqXw5fb3uSPrvrLYV8m31Y6+BC4AMEOCHgA6JugBoGOCHgA6JugBoGOCHgA6\nJugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGM7z7oBmHsr9J7yO+067J7u\n73/shwfVP/MTr5u49oD846CxYSUxoweAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiY\noAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiY29QCE7nz2U8ZVP+Ynb80qH7vC1YNqod5YUYPAB0T\n9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQ\nMUEPAB1zP3pgItcfNWyecNt9Px5U/+BPXDFx7YZBI8PKYkYPAB0T9ADQMUEPAB0T9ADQMUEPAB0T\n9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMbepBSby757+9UH1r7ruuEH1\nG9atG1QP82LwjL6q9qqql1XV31TVVVX146q6rao+X1UvraqdNnv9PlXVtvA4Z2hPAMDINGb0JyV5\nX5Ibkpyf5LokD0/ym0nOTHJcVZ3UWmub1X0tyUcXeL/Lp9ATAJDpBP2VSY5P8vHW2n0bV1bV7yf5\nhyTPyyj0P7JZ3aWttTVTGB8AWMTgP9231j7bWvvYpiE/Xn9jkvePnx4xdBwAYPvt6JPxfjJerl9g\n2yOq6uVJ9kpyS5IvttYu28H9AMBc2WFBX1U7J3nx+OknF3jJs8aPTWsuSHJya+26HdUXAMyTHTmj\nf0eSJyU5r7X2qU3W35XkbRmdiHf1eN1TkqxJcmSSz1TV01prd25tgKpau8imx0/aNAD0ZIdcMKeq\nXpPk1CTfSPKiTbe11m5qrf1ha+0rrbV148eFSY5J8uUkP5/kZTuiLwCYN1Of0VfVq5OcnuTrSY5u\nrd26LXWttfVVdWaSQ5IcPn6PrdUctEgPa5McuM1NA0Cnpjqjr6pTkpyR0Xfhjxyfeb89fjBerp5m\nXwAwr6YW9FX1xiTvSnJpRiF/0wRv84zx8uotvgoA2CZTCfqqenNGJ9+tzejP9Tdv4bUHbn5Z3PH6\no5O8bvz07Gn0BQDzbvBn9FV1cpK3JtmQ5KIkr6mqzV92bWvtrPHP70yyf1VdnOT68bqnJDlq/POb\nW2sXD+0LAJjOyXj7jperkpyyyGs+l+Ss8c8fTPLcJL+Y5Lgk90vy/SQfTvKe1tpFU+gJAMgUgn58\nvfo12/H6DyT5wNBxAYCtcz96YCJX/8kTBtU/4Af3DqrfKV8dVA/zYodcMAcAWB4EPQB0TNADQMcE\nPQB0TNADQMcEPQB0TNADQMcEPQB0TNADQMcEPQB0TNADQMcEPQB0TNADQMcEPQB0zG1qgYmsPvfL\ns24B2AZm9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEP\nAB0T9ADQMUEPAB2r1tqse5i6qrplp6x6yOo8aNatAMBE7swduS8bbm2t7TXkfXq9H/3t92VD7si6\naxfZ/vjx8htL1E8P7LPJ2G+Tsd+2n302meW83/ZJcvvQN+lyRr81VbU2SVprB826l5XCPpuM/TYZ\n+2372WeTmYf95jN6AOiYoAeAjgl6AOiYoAeAjgl6AOjYXJ51DwDzwoweADom6AGgY4IeADom6AGg\nY4IeADom6AGgY4IeADo2V0FfVY+qqr+oqu9V1T1VdW1VnVZVD551b8vVeB+1RR43zrq/WamqE6vq\njKq6qKpuH++Ps7dSc2hVnVdVt1bVj6vqsqo6papWLVXfs7Y9+62q9tnCsdeq6pyl7n8WqmqvqnpZ\nVf1NVV01PnZuq6rPV9VLq2rB/47P+/G2vfut5+Ot1/vR/4yqemySi5M8LMnfZnTv4acneW2SY6vq\nsNbaLTNscTm7LclpC6z/0VI3soy8KclTM9oH1+en97ReUFX9RpKPJLk7yYeS3Jrk15O8K8lhSU7a\nkc0uI9u138a+luSjC6y/fIp9LWcnJXlfkhuSnJ/kuiQPT/KbSc5MclxVndQ2ufqZ4y3JBPttrL/j\nrbU2F48kn0rSkvynzda/c7z+/bPucTk+klyb5NpZ97HcHkmOTLJ/kkpyxPgYOnuR1+6e5KYk9yQ5\neJP1u2b0y2dL8oJZ/5uW4X7bZ7z9rFn3PeN9dlRGIb3TZuv3zii8WpLnbbLe8TbZfuv2eJuLP92P\nZ/PHZBRaf7rZ5j9KcmeSF1XV6iVujRWqtXZ+a+1bbfxfiK04MclDk5zTWrtkk/e4O6MZbpK8cge0\nuexs534jSWvts621j7XW7tts/Y1J3j9+esQmmxxvmWi/dWte/nR/5Hj56QX+R7+jqr6Q0S8Cz0jy\nmaVubgXYpapemOQxGf1SdFmSC1trG2bb1opx1Hj5yQW2XZjkriSHVtUurbV7lq6tFeMRVfXyJHsl\nuSXJF1trl824p+XiJ+Pl+k3WOd62bqH9tlF3x9u8BP3jxssrF9n+rYyC/oAI+oXsneSDm627pqpe\n0lr73CwaWmEWPf5aa+ur6pokT0yyX5IrlrKxFeJZ48e/qKoLkpzcWrtuJh0tA1W1c5IXj59uGuqO\nty3Ywn7bqLvjbS7+dJ9kj/HytkW2b1y/5xL0stL8ZZKjMwr71UmenOTPMvo86xNV9dTZtbZiOP4m\nc1eStyU5KMmDx49nZnRi1RFJPjPnH7e9I8mTkpzXWvvUJusdb1u22H7r9nibl6BnQq21t4w/6/p+\na+2u1trlrbVXZHQS4wOSrJlth/SqtXZTa+0PW2tfaa2tGz8uzOivb19O8vNJXjbbLmejql6T5NSM\nvj30ohm3s2Jsab/1fLzNS9Bv/A12j0W2b1y/bgl66cXGk1kOn2kXK4Pjb4paa+sz+npUMofHX1W9\nOsnpSb6e5MjW2q2bvcTxtoBt2G8L6uF4m5eg/+Z4ecAi2/cfLxf7DJ+f9YPxckX+KWuJLXr8jT8v\n3Dejk4KuXsqmVri5PP6q6pQkZ2T0ne4jx2eQb87xtplt3G9bsqKPt3kJ+vPHy2MWuBrSgzK6gMRd\nSb601I2tYM8YL+fmPxYDfHa8PHaBbYcn2S3JxXN8BvQk5u74q6o3ZnTBm0szCqubFnmp420T27Hf\ntmRFH29zEfSttX9O8umMTiB71Wab35LRb2kfbK3ducStLWtV9YSFTj6pqn2SvGf8dIuXfSVJcm6S\nm5O8oKoO3riyqnZN8vbx0/fNorHlrKoOXOjyrlV1dJLXjZ/OxfFXVW/O6CSytUmObq3dvIWXO97G\ntme/9Xy81bxct2KBS+BekeSQjL5jf2WSQ5tL4P4rVbUmoxNXLkzy7SR3JHlskudkdJWt85I8t7V2\n76x6nJWqOiHJCeOneyd5dka/7V80Xndza+0Nm73+3IwuSXpORpckPT6jr0Kdm+S35uEiMtuz38Zf\nado/o//fXj/e/pT89Hvib26tbQyublXVyUnOSrIhoz8/L3Q2/bWttbM2qZn7421791vXx9usL823\nlI8kj87o62I3JLk3o/A6LcmDZ93bcnxk9NWS/5XRGarrMrrIxA+S/N+Mvodas+5xhvtmTUaXy1zs\nce0CNYdl9MvRD5P8OMn/y2imsGrW/57luN+SvDTJ/8noipY/yuiSrtdldO32X571v2UZ7bOW5ALH\n27D91vPxNjczegCYR3PxGT0AzCtBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFB\nDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0LH/DzGBCzTeSZJ4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f332420ef98>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "index = 0\n",
    "train_features, train_labels = pickle.load(open('data/batch0', mode='rb'))\n",
    "print(type(train_features))\n",
    "print('%d 条' % len(train_features))\n",
    "print(train_labels.shape)\n",
    "print(train_labels[index])\n",
    "\n",
    "image = Image.fromarray(train_features[index].reshape(28,28)*255)\n",
    "image = image.convert('L')\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检查点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_features, valid_labels = pickle.load(open('data/batch0', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net_image_input(image_shape):\n",
    "    return tf.placeholder(tf.float32, (None, image_shape[0], image_shape[1], image_shape[2]), name='x')\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    return tf.placeholder(tf.float32, (None, n_classes), name='y')\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    weight = tf.Variable(tf.truncated_normal((list(conv_ksize) + [x_tensor.get_shape().as_list()[3], conv_num_outputs]), stddev=0.04))\n",
    "    bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    # 2D Convolution Layer\n",
    "    output = tf.nn.conv2d(x_tensor,\n",
    "                          weight,\n",
    "                          [1, conv_strides[0], conv_strides[1], 1],\n",
    "                          padding='SAME')\n",
    "    output = tf.nn.bias_add(output, bias)\n",
    "    # Pooling Layer\n",
    "    output = tf.nn.max_pool(output,\n",
    "                          [1, pool_ksize[0], pool_ksize[1], 1],\n",
    "                          [1, pool_strides[0], pool_strides[1], 1],\n",
    "                          padding='SAME')\n",
    "    return output\n",
    "\n",
    "def flatten(x_tensor):\n",
    "    shape = x_tensor.get_shape().as_list()\n",
    "    return tf.reshape(x_tensor, [-1, shape[1]*shape[2]*shape[3]])\n",
    "\n",
    "\n",
    "def fully_conn(x_tensor, num_outputs):\n",
    "    weight = tf.Variable(tf.truncated_normal((x_tensor.get_shape().as_list()[1], num_outputs), stddev=0.04))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    output = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    return tf.nn.relu(output)\n",
    "\n",
    "def output(x_tensor, num_outputs):\n",
    "    weight = tf.Variable(tf.truncated_normal((x_tensor.get_shape().as_list()[1], num_outputs), stddev=0.04))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    output = tf.add(tf.matmul(x_tensor, weight) , bias)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "def conv_net(x, keep_prob):\n",
    "    conv = conv2d_maxpool(x,\n",
    "                           conv_num_outputs=64,\n",
    "                           conv_ksize=[3,3],\n",
    "                           conv_strides=[1,1],\n",
    "                           pool_ksize=[2,2],\n",
    "                           pool_strides=[2,2])\n",
    "    \n",
    "    conv = conv2d_maxpool(conv,\n",
    "                          conv_num_outputs=128,\n",
    "                          conv_ksize=[3,3],\n",
    "                          conv_strides=[1,1],\n",
    "                          pool_ksize=[2,2],\n",
    "                          pool_strides=[2,2])\n",
    "    \n",
    "    conv = conv2d_maxpool(conv,\n",
    "                          conv_num_outputs=256,\n",
    "                          conv_ksize=[3,3],\n",
    "                          conv_strides=[1,1],\n",
    "                          pool_ksize=[2,2],\n",
    "                          pool_strides=[2,2])\n",
    "    \n",
    "    conv = conv2d_maxpool(conv,\n",
    "                          conv_num_outputs=512,\n",
    "                          conv_ksize=[3,3],\n",
    "                          conv_strides=[1,1],\n",
    "                          pool_ksize=[2,2],\n",
    "                          pool_strides=[2,2])\n",
    "    \n",
    "    conv = conv2d_maxpool(conv,\n",
    "                          conv_num_outputs=1024,\n",
    "                          conv_ksize=[3,3],\n",
    "                          conv_strides=[1,1],\n",
    "                          pool_ksize=[2,2],\n",
    "                          pool_strides=[2,2])\n",
    "\n",
    "    flt = flatten(conv)\n",
    "\n",
    "    fc = fully_conn(flt, 512)\n",
    "    fc = fully_conn(fc, 512)\n",
    "    fc = fully_conn(fc, 1024)\n",
    "    fc = tf.nn.dropout(fc, keep_prob)\n",
    "    \n",
    "    o = output(fc, len(image_names))\n",
    "    return o\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((28, 28, 1))\n",
    "y = neural_net_label_input(len(image_names))\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    session.run(optimizer, feed_dict={x:feature_batch,\n",
    "                                      y:label_batch,\n",
    "                                      keep_prob:keep_probability})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch,\n",
    "                                     y: label_batch,\n",
    "                                     keep_prob: 1.})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x: valid_features,\n",
    "                                              y: valid_labels,\n",
    "                                              keep_prob: 1.})\n",
    "    print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))\n",
    "    return valid_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 1\n",
    "keep_probability = 0.75\n",
    "break_percent = 0.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     0.4967 Validation Accuracy: 0.077333\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     0.3448 Validation Accuracy: 0.066000\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     0.2644 Validation Accuracy: 0.066667\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     0.2898 Validation Accuracy: 0.066667\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     0.2693 Validation Accuracy: 0.066667\n",
      "Epoch  1, CIFAR-10 Batch 6:  Loss:     0.2588 Validation Accuracy: 0.069333\n",
      "Epoch  1, CIFAR-10 Batch 7:  Loss:     0.2744 Validation Accuracy: 0.092000\n",
      "Epoch  1, CIFAR-10 Batch 8:  Loss:     0.2488 Validation Accuracy: 0.066667\n",
      "Epoch  1, CIFAR-10 Batch 9:  Loss:     0.2565 Validation Accuracy: 0.116667\n",
      "Epoch  1, CIFAR-10 Batch 10:  Loss:     0.2579 Validation Accuracy: 0.067333\n",
      "Epoch  1, CIFAR-10 Batch 11:  Loss:     0.2443 Validation Accuracy: 0.068000\n",
      "Epoch  1, CIFAR-10 Batch 12:  Loss:     0.2517 Validation Accuracy: 0.068000\n",
      "Epoch  1, CIFAR-10 Batch 13:  Loss:     0.2497 Validation Accuracy: 0.074667\n",
      "Epoch  1, CIFAR-10 Batch 14:  Loss:     0.2394 Validation Accuracy: 0.104667\n",
      "Epoch  1, CIFAR-10 Batch 15:  Loss:     0.2435 Validation Accuracy: 0.250667\n",
      "Epoch  1, CIFAR-10 Batch 16:  Loss:     0.2407 Validation Accuracy: 0.322667\n",
      "Epoch  1, CIFAR-10 Batch 17:  Loss:     0.2323 Validation Accuracy: 0.332000\n",
      "Epoch  1, CIFAR-10 Batch 18:  Loss:     0.2342 Validation Accuracy: 0.331333\n",
      "Epoch  1, CIFAR-10 Batch 19:  Loss:     0.2276 Validation Accuracy: 0.304667\n",
      "Epoch  1, CIFAR-10 Batch 20:  Loss:     0.2192 Validation Accuracy: 0.318667\n",
      "Epoch  1, CIFAR-10 Batch 21:  Loss:     0.2169 Validation Accuracy: 0.360000\n",
      "Epoch  1, CIFAR-10 Batch 22:  Loss:     0.2081 Validation Accuracy: 0.389333\n",
      "Epoch  1, CIFAR-10 Batch 23:  Loss:     0.1996 Validation Accuracy: 0.408000\n",
      "Epoch  1, CIFAR-10 Batch 24:  Loss:     0.1952 Validation Accuracy: 0.427333\n",
      "Epoch  1, CIFAR-10 Batch 25:  Loss:     0.1870 Validation Accuracy: 0.452667\n",
      "Epoch  1, CIFAR-10 Batch 26:  Loss:     0.1764 Validation Accuracy: 0.483333\n",
      "Epoch  1, CIFAR-10 Batch 27:  Loss:     0.1709 Validation Accuracy: 0.479333\n",
      "Epoch  1, CIFAR-10 Batch 28:  Loss:     0.1638 Validation Accuracy: 0.492000\n",
      "Epoch  1, CIFAR-10 Batch 29:  Loss:     0.1596 Validation Accuracy: 0.543333\n",
      "Epoch  1, CIFAR-10 Batch 30:  Loss:     0.1535 Validation Accuracy: 0.556667\n",
      "Epoch  1, CIFAR-10 Batch 31:  Loss:     0.1495 Validation Accuracy: 0.570667\n",
      "Epoch  1, CIFAR-10 Batch 32:  Loss:     0.1490 Validation Accuracy: 0.548667\n",
      "Epoch  1, CIFAR-10 Batch 33:  Loss:     0.1412 Validation Accuracy: 0.570667\n",
      "Epoch  1, CIFAR-10 Batch 34:  Loss:     0.1368 Validation Accuracy: 0.602000\n",
      "Epoch  1, CIFAR-10 Batch 35:  Loss:     0.1361 Validation Accuracy: 0.579333\n",
      "Epoch  1, CIFAR-10 Batch 36:  Loss:     0.1330 Validation Accuracy: 0.606000\n",
      "Epoch  1, CIFAR-10 Batch 37:  Loss:     0.1305 Validation Accuracy: 0.619333\n",
      "Epoch  1, CIFAR-10 Batch 38:  Loss:     0.1298 Validation Accuracy: 0.612667\n",
      "Epoch  1, CIFAR-10 Batch 39:  Loss:     0.1211 Validation Accuracy: 0.630000\n",
      "Epoch  1, CIFAR-10 Batch 40:  Loss:     0.1163 Validation Accuracy: 0.652000\n",
      "Epoch  1, CIFAR-10 Batch 41:  Loss:     0.1130 Validation Accuracy: 0.659333\n",
      "Epoch  1, CIFAR-10 Batch 42:  Loss:     0.1194 Validation Accuracy: 0.657333\n",
      "Epoch  1, CIFAR-10 Batch 43:  Loss:     0.1129 Validation Accuracy: 0.672667\n",
      "Epoch  1, CIFAR-10 Batch 44:  Loss:     0.1061 Validation Accuracy: 0.687333\n",
      "Epoch  1, CIFAR-10 Batch 45:  Loss:     0.1031 Validation Accuracy: 0.681333\n",
      "Epoch  1, CIFAR-10 Batch 46:  Loss:     0.1052 Validation Accuracy: 0.694000\n",
      "Epoch  1, CIFAR-10 Batch 47:  Loss:     0.1077 Validation Accuracy: 0.700667\n",
      "Epoch  1, CIFAR-10 Batch 48:  Loss:     0.1046 Validation Accuracy: 0.708000\n",
      "Epoch  1, CIFAR-10 Batch 49:  Loss:     0.0977 Validation Accuracy: 0.722667\n",
      "Epoch  1, CIFAR-10 Batch 50:  Loss:     0.0940 Validation Accuracy: 0.716667\n",
      "Epoch  1, CIFAR-10 Batch 51:  Loss:     0.0923 Validation Accuracy: 0.729333\n",
      "Epoch  1, CIFAR-10 Batch 52:  Loss:     0.0903 Validation Accuracy: 0.741333\n",
      "Epoch  1, CIFAR-10 Batch 53:  Loss:     0.0884 Validation Accuracy: 0.752667\n",
      "Epoch  1, CIFAR-10 Batch 54:  Loss:     0.0906 Validation Accuracy: 0.754000\n",
      "Epoch  1, CIFAR-10 Batch 55:  Loss:     0.0887 Validation Accuracy: 0.756000\n",
      "Epoch  1, CIFAR-10 Batch 56:  Loss:     0.0828 Validation Accuracy: 0.772667\n",
      "Epoch  1, CIFAR-10 Batch 57:  Loss:     0.0806 Validation Accuracy: 0.776667\n",
      "Epoch  1, CIFAR-10 Batch 58:  Loss:     0.0794 Validation Accuracy: 0.784667\n",
      "Epoch  1, CIFAR-10 Batch 59:  Loss:     0.0724 Validation Accuracy: 0.800667\n",
      "Epoch  1, CIFAR-10 Batch 60:  Loss:     0.0788 Validation Accuracy: 0.796667\n",
      "Epoch  1, CIFAR-10 Batch 61:  Loss:     0.0705 Validation Accuracy: 0.818667\n",
      "Epoch  1, CIFAR-10 Batch 62:  Loss:     0.0699 Validation Accuracy: 0.801333\n",
      "Epoch  1, CIFAR-10 Batch 63:  Loss:     0.0732 Validation Accuracy: 0.814667\n",
      "Epoch  1, CIFAR-10 Batch 64:  Loss:     0.0654 Validation Accuracy: 0.824000\n",
      "Epoch  1, CIFAR-10 Batch 65:  Loss:     0.0659 Validation Accuracy: 0.826000\n",
      "Epoch  1, CIFAR-10 Batch 66:  Loss:     0.0679 Validation Accuracy: 0.831333\n",
      "Epoch  1, CIFAR-10 Batch 67:  Loss:     0.0595 Validation Accuracy: 0.842667\n",
      "Epoch  1, CIFAR-10 Batch 68:  Loss:     0.0591 Validation Accuracy: 0.828667\n",
      "Epoch  1, CIFAR-10 Batch 69:  Loss:     0.0591 Validation Accuracy: 0.836667\n",
      "Epoch  1, CIFAR-10 Batch 70:  Loss:     0.0604 Validation Accuracy: 0.846000\n",
      "Epoch  1, CIFAR-10 Batch 71:  Loss:     0.0605 Validation Accuracy: 0.848000\n",
      "Epoch  1, CIFAR-10 Batch 72:  Loss:     0.0553 Validation Accuracy: 0.861333\n",
      "Epoch  1, CIFAR-10 Batch 73:  Loss:     0.0567 Validation Accuracy: 0.861333\n",
      "Epoch  1, CIFAR-10 Batch 74:  Loss:     0.0557 Validation Accuracy: 0.858000\n",
      "Epoch  1, CIFAR-10 Batch 75:  Loss:     0.0488 Validation Accuracy: 0.867333\n",
      "Epoch  1, CIFAR-10 Batch 76:  Loss:     0.0521 Validation Accuracy: 0.860000\n",
      "Epoch  1, CIFAR-10 Batch 77:  Loss:     0.0534 Validation Accuracy: 0.876667\n",
      "Epoch  1, CIFAR-10 Batch 78:  Loss:     0.0517 Validation Accuracy: 0.870667\n",
      "Epoch  1, CIFAR-10 Batch 79:  Loss:     0.0467 Validation Accuracy: 0.874667\n",
      "Epoch  1, CIFAR-10 Batch 80:  Loss:     0.0476 Validation Accuracy: 0.882000\n",
      "Epoch  1, CIFAR-10 Batch 81:  Loss:     0.0436 Validation Accuracy: 0.882667\n",
      "Epoch  1, CIFAR-10 Batch 82:  Loss:     0.0494 Validation Accuracy: 0.883333\n",
      "Epoch  1, CIFAR-10 Batch 83:  Loss:     0.0461 Validation Accuracy: 0.892000\n",
      "Epoch  1, CIFAR-10 Batch 84:  Loss:     0.0455 Validation Accuracy: 0.896667\n",
      "Epoch  1, CIFAR-10 Batch 85:  Loss:     0.0414 Validation Accuracy: 0.895333\n",
      "Epoch  1, CIFAR-10 Batch 86:  Loss:     0.0397 Validation Accuracy: 0.890000\n",
      "Epoch  1, CIFAR-10 Batch 87:  Loss:     0.0462 Validation Accuracy: 0.902667\n",
      "Epoch  1, CIFAR-10 Batch 88:  Loss:     0.0428 Validation Accuracy: 0.902000\n",
      "Epoch  1, CIFAR-10 Batch 89:  Loss:     0.0396 Validation Accuracy: 0.904000\n",
      "Epoch  1, CIFAR-10 Batch 90:  Loss:     0.0414 Validation Accuracy: 0.897333\n",
      "Epoch  1, CIFAR-10 Batch 91:  Loss:     0.0460 Validation Accuracy: 0.903333\n",
      "Epoch  1, CIFAR-10 Batch 92:  Loss:     0.0414 Validation Accuracy: 0.900000\n",
      "Epoch  1, CIFAR-10 Batch 93:  Loss:     0.0353 Validation Accuracy: 0.900667\n",
      "Epoch  1, CIFAR-10 Batch 94:  Loss:     0.0383 Validation Accuracy: 0.900667\n",
      "Epoch  1, CIFAR-10 Batch 95:  Loss:     0.0366 Validation Accuracy: 0.898000\n",
      "Epoch  1, CIFAR-10 Batch 96:  Loss:     0.0376 Validation Accuracy: 0.905333\n",
      "Epoch  1, CIFAR-10 Batch 97:  Loss:     0.0446 Validation Accuracy: 0.899333\n",
      "Epoch  1, CIFAR-10 Batch 98:  Loss:     0.0367 Validation Accuracy: 0.902000\n",
      "Epoch  1, CIFAR-10 Batch 99:  Loss:     0.0426 Validation Accuracy: 0.908667\n",
      "Epoch  1, CIFAR-10 Batch 100:  Loss:     0.0388 Validation Accuracy: 0.910000\n",
      "Epoch  1, CIFAR-10 Batch 101:  Loss:     0.0364 Validation Accuracy: 0.912000\n",
      "Epoch  1, CIFAR-10 Batch 102:  Loss:     0.0391 Validation Accuracy: 0.902667\n",
      "Epoch  1, CIFAR-10 Batch 103:  Loss:     0.0361 Validation Accuracy: 0.910000\n",
      "Epoch  1, CIFAR-10 Batch 104:  Loss:     0.0355 Validation Accuracy: 0.913333\n",
      "Epoch  1, CIFAR-10 Batch 105:  Loss:     0.0344 Validation Accuracy: 0.908000\n",
      "Epoch  1, CIFAR-10 Batch 106:  Loss:     0.0337 Validation Accuracy: 0.909333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, CIFAR-10 Batch 107:  Loss:     0.0396 Validation Accuracy: 0.912000\n",
      "Epoch  1, CIFAR-10 Batch 108:  Loss:     0.0364 Validation Accuracy: 0.908667\n",
      "Epoch  1, CIFAR-10 Batch 109:  Loss:     0.0373 Validation Accuracy: 0.908000\n",
      "Epoch  1, CIFAR-10 Batch 110:  Loss:     0.0392 Validation Accuracy: 0.913333\n",
      "Epoch  1, CIFAR-10 Batch 111:  Loss:     0.0357 Validation Accuracy: 0.907333\n",
      "Epoch  1, CIFAR-10 Batch 112:  Loss:     0.0371 Validation Accuracy: 0.910000\n",
      "Epoch  1, CIFAR-10 Batch 113:  Loss:     0.0358 Validation Accuracy: 0.906000\n",
      "Epoch  1, CIFAR-10 Batch 114:  Loss:     0.0345 Validation Accuracy: 0.908667\n",
      "Epoch  1, CIFAR-10 Batch 115:  Loss:     0.0349 Validation Accuracy: 0.913333\n",
      "Epoch  1, CIFAR-10 Batch 116:  Loss:     0.0368 Validation Accuracy: 0.909333\n",
      "Epoch  1, CIFAR-10 Batch 117:  Loss:     0.0356 Validation Accuracy: 0.918667\n",
      "Epoch  1, CIFAR-10 Batch 118:  Loss:     0.0329 Validation Accuracy: 0.921333\n",
      "Epoch  1, CIFAR-10 Batch 119:  Loss:     0.0342 Validation Accuracy: 0.908000\n",
      "Epoch  1, CIFAR-10 Batch 120:  Loss:     0.0316 Validation Accuracy: 0.922000\n",
      "Epoch  1, CIFAR-10 Batch 121:  Loss:     0.0313 Validation Accuracy: 0.910667\n",
      "Epoch  1, CIFAR-10 Batch 122:  Loss:     0.0308 Validation Accuracy: 0.913333\n",
      "Epoch  1, CIFAR-10 Batch 123:  Loss:     0.0314 Validation Accuracy: 0.923333\n",
      "Epoch  1, CIFAR-10 Batch 124:  Loss:     0.0299 Validation Accuracy: 0.921333\n",
      "Epoch  1, CIFAR-10 Batch 125:  Loss:     0.0292 Validation Accuracy: 0.914667\n",
      "Epoch  1, CIFAR-10 Batch 126:  Loss:     0.0323 Validation Accuracy: 0.914667\n",
      "Epoch  1, CIFAR-10 Batch 127:  Loss:     0.0309 Validation Accuracy: 0.918667\n",
      "Epoch  1, CIFAR-10 Batch 128:  Loss:     0.0317 Validation Accuracy: 0.922667\n",
      "Epoch  1, CIFAR-10 Batch 129:  Loss:     0.0334 Validation Accuracy: 0.916667\n",
      "Epoch  1, CIFAR-10 Batch 130:  Loss:     0.0318 Validation Accuracy: 0.924667\n",
      "Epoch  1, CIFAR-10 Batch 131:  Loss:     0.0327 Validation Accuracy: 0.924000\n",
      "Epoch  1, CIFAR-10 Batch 132:  Loss:     0.0297 Validation Accuracy: 0.926667\n",
      "Epoch  1, CIFAR-10 Batch 133:  Loss:     0.0333 Validation Accuracy: 0.922667\n",
      "Epoch  1, CIFAR-10 Batch 134:  Loss:     0.0280 Validation Accuracy: 0.923333\n",
      "Epoch  1, CIFAR-10 Batch 135:  Loss:     0.0300 Validation Accuracy: 0.918000\n",
      "Epoch  1, CIFAR-10 Batch 136:  Loss:     0.0336 Validation Accuracy: 0.924000\n",
      "Epoch  1, CIFAR-10 Batch 137:  Loss:     0.0332 Validation Accuracy: 0.930667\n",
      "Epoch  1, CIFAR-10 Batch 138:  Loss:     0.0346 Validation Accuracy: 0.925333\n",
      "Epoch  1, CIFAR-10 Batch 139:  Loss:     0.0289 Validation Accuracy: 0.926000\n",
      "Epoch  1, CIFAR-10 Batch 140:  Loss:     0.0311 Validation Accuracy: 0.926000\n",
      "Epoch  1, CIFAR-10 Batch 141:  Loss:     0.0314 Validation Accuracy: 0.925333\n",
      "Epoch  1, CIFAR-10 Batch 142:  Loss:     0.0305 Validation Accuracy: 0.930667\n",
      "Epoch  1, CIFAR-10 Batch 143:  Loss:     0.0273 Validation Accuracy: 0.925333\n",
      "Epoch  1, CIFAR-10 Batch 144:  Loss:     0.0302 Validation Accuracy: 0.928000\n",
      "Epoch  1, CIFAR-10 Batch 145:  Loss:     0.0338 Validation Accuracy: 0.928667\n",
      "Epoch  1, CIFAR-10 Batch 146:  Loss:     0.0271 Validation Accuracy: 0.932667\n",
      "Epoch  1, CIFAR-10 Batch 147:  Loss:     0.0266 Validation Accuracy: 0.932667\n",
      "Epoch  1, CIFAR-10 Batch 148:  Loss:     0.0276 Validation Accuracy: 0.935333\n",
      "Epoch  1, CIFAR-10 Batch 149:  Loss:     0.0282 Validation Accuracy: 0.936000\n",
      "Epoch  1, CIFAR-10 Batch 150:  Loss:     0.0264 Validation Accuracy: 0.930667\n",
      "Epoch  1, CIFAR-10 Batch 151:  Loss:     0.0269 Validation Accuracy: 0.928000\n",
      "Epoch  1, CIFAR-10 Batch 152:  Loss:     0.0212 Validation Accuracy: 0.926667\n",
      "Epoch  1, CIFAR-10 Batch 153:  Loss:     0.0262 Validation Accuracy: 0.933333\n",
      "Epoch  1, CIFAR-10 Batch 154:  Loss:     0.0269 Validation Accuracy: 0.930000\n",
      "Epoch  1, CIFAR-10 Batch 155:  Loss:     0.0253 Validation Accuracy: 0.931333\n",
      "Epoch  1, CIFAR-10 Batch 156:  Loss:     0.0255 Validation Accuracy: 0.926000\n",
      "Epoch  1, CIFAR-10 Batch 157:  Loss:     0.0264 Validation Accuracy: 0.920667\n",
      "Epoch  1, CIFAR-10 Batch 158:  Loss:     0.0265 Validation Accuracy: 0.926667\n",
      "Epoch  1, CIFAR-10 Batch 159:  Loss:     0.0259 Validation Accuracy: 0.927333\n",
      "Epoch  1, CIFAR-10 Batch 160:  Loss:     0.0269 Validation Accuracy: 0.934000\n",
      "Epoch  1, CIFAR-10 Batch 161:  Loss:     0.0273 Validation Accuracy: 0.934667\n",
      "Epoch  1, CIFAR-10 Batch 162:  Loss:     0.0287 Validation Accuracy: 0.934667\n",
      "Epoch  1, CIFAR-10 Batch 163:  Loss:     0.0239 Validation Accuracy: 0.932000\n",
      "Epoch  1, CIFAR-10 Batch 164:  Loss:     0.0269 Validation Accuracy: 0.934000\n",
      "Epoch  1, CIFAR-10 Batch 165:  Loss:     0.0253 Validation Accuracy: 0.934000\n",
      "Epoch  1, CIFAR-10 Batch 166:  Loss:     0.0271 Validation Accuracy: 0.929333\n",
      "Epoch  1, CIFAR-10 Batch 167:  Loss:     0.0246 Validation Accuracy: 0.935333\n",
      "Epoch  1, CIFAR-10 Batch 168:  Loss:     0.0247 Validation Accuracy: 0.930667\n",
      "Epoch  1, CIFAR-10 Batch 169:  Loss:     0.0256 Validation Accuracy: 0.934000\n",
      "Epoch  1, CIFAR-10 Batch 170:  Loss:     0.0280 Validation Accuracy: 0.929333\n",
      "Epoch  1, CIFAR-10 Batch 171:  Loss:     0.0237 Validation Accuracy: 0.934667\n",
      "Epoch  1, CIFAR-10 Batch 172:  Loss:     0.0242 Validation Accuracy: 0.930000\n",
      "Epoch  1, CIFAR-10 Batch 173:  Loss:     0.0252 Validation Accuracy: 0.933333\n",
      "Epoch  1, CIFAR-10 Batch 174:  Loss:     0.0256 Validation Accuracy: 0.932667\n",
      "Epoch  1, CIFAR-10 Batch 175:  Loss:     0.0289 Validation Accuracy: 0.929333\n",
      "Epoch  1, CIFAR-10 Batch 176:  Loss:     0.0246 Validation Accuracy: 0.938000\n",
      "Epoch  1, CIFAR-10 Batch 177:  Loss:     0.0262 Validation Accuracy: 0.934000\n",
      "Epoch  1, CIFAR-10 Batch 178:  Loss:     0.0304 Validation Accuracy: 0.930000\n",
      "Epoch  1, CIFAR-10 Batch 179:  Loss:     0.0221 Validation Accuracy: 0.936000\n",
      "Epoch  1, CIFAR-10 Batch 180:  Loss:     0.0262 Validation Accuracy: 0.929333\n",
      "Epoch  1, CIFAR-10 Batch 181:  Loss:     0.0257 Validation Accuracy: 0.931333\n",
      "Epoch  1, CIFAR-10 Batch 182:  Loss:     0.0257 Validation Accuracy: 0.938667\n",
      "Epoch  1, CIFAR-10 Batch 183:  Loss:     0.0277 Validation Accuracy: 0.928667\n",
      "Epoch  1, CIFAR-10 Batch 184:  Loss:     0.0238 Validation Accuracy: 0.937333\n",
      "Epoch  1, CIFAR-10 Batch 185:  Loss:     0.0289 Validation Accuracy: 0.936667\n",
      "Epoch  1, CIFAR-10 Batch 186:  Loss:     0.0256 Validation Accuracy: 0.928667\n",
      "Epoch  1, CIFAR-10 Batch 187:  Loss:     0.0323 Validation Accuracy: 0.928000\n",
      "Epoch  1, CIFAR-10 Batch 188:  Loss:     0.0276 Validation Accuracy: 0.932000\n",
      "Epoch  1, CIFAR-10 Batch 189:  Loss:     0.0259 Validation Accuracy: 0.932000\n",
      "Epoch  1, CIFAR-10 Batch 190:  Loss:     0.0242 Validation Accuracy: 0.937333\n",
      "Epoch  1, CIFAR-10 Batch 191:  Loss:     0.0307 Validation Accuracy: 0.940667\n",
      "Epoch  1, CIFAR-10 Batch 192:  Loss:     0.0279 Validation Accuracy: 0.931333\n",
      "Epoch  1, CIFAR-10 Batch 193:  Loss:     0.0306 Validation Accuracy: 0.929333\n",
      "Epoch  1, CIFAR-10 Batch 194:  Loss:     0.0262 Validation Accuracy: 0.933333\n",
      "Epoch  1, CIFAR-10 Batch 195:  Loss:     0.0223 Validation Accuracy: 0.933333\n",
      "Epoch  1, CIFAR-10 Batch 196:  Loss:     0.0257 Validation Accuracy: 0.943333\n",
      "Epoch  1, CIFAR-10 Batch 197:  Loss:     0.0273 Validation Accuracy: 0.938000\n",
      "Epoch  1, CIFAR-10 Batch 198:  Loss:     0.0250 Validation Accuracy: 0.934000\n",
      "Epoch  1, CIFAR-10 Batch 199:  Loss:     0.0249 Validation Accuracy: 0.934000\n",
      "Epoch  1, CIFAR-10 Batch 200:  Loss:     0.0281 Validation Accuracy: 0.932000\n",
      "Epoch  1, CIFAR-10 Batch 201:  Loss:     0.0213 Validation Accuracy: 0.936667\n",
      "Epoch  1, CIFAR-10 Batch 202:  Loss:     0.0231 Validation Accuracy: 0.942000\n",
      "Epoch  1, CIFAR-10 Batch 203:  Loss:     0.0209 Validation Accuracy: 0.938667\n",
      "Epoch  1, CIFAR-10 Batch 204:  Loss:     0.0205 Validation Accuracy: 0.939333\n",
      "Epoch  1, CIFAR-10 Batch 205:  Loss:     0.0211 Validation Accuracy: 0.942667\n",
      "Epoch  1, CIFAR-10 Batch 206:  Loss:     0.0220 Validation Accuracy: 0.936667\n",
      "Epoch  1, CIFAR-10 Batch 207:  Loss:     0.0230 Validation Accuracy: 0.940000\n",
      "Epoch  1, CIFAR-10 Batch 208:  Loss:     0.0245 Validation Accuracy: 0.942000\n",
      "Epoch  1, CIFAR-10 Batch 209:  Loss:     0.0262 Validation Accuracy: 0.936000\n",
      "Epoch  1, CIFAR-10 Batch 210:  Loss:     0.0240 Validation Accuracy: 0.934000\n",
      "Epoch  1, CIFAR-10 Batch 211:  Loss:     0.0243 Validation Accuracy: 0.935333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, CIFAR-10 Batch 212:  Loss:     0.0258 Validation Accuracy: 0.936000\n",
      "Epoch  1, CIFAR-10 Batch 213:  Loss:     0.0247 Validation Accuracy: 0.942000\n",
      "Epoch  1, CIFAR-10 Batch 214:  Loss:     0.0220 Validation Accuracy: 0.934000\n",
      "Epoch  1, CIFAR-10 Batch 215:  Loss:     0.0221 Validation Accuracy: 0.938667\n",
      "Epoch  1, CIFAR-10 Batch 216:  Loss:     0.0233 Validation Accuracy: 0.939333\n",
      "Epoch  1, CIFAR-10 Batch 217:  Loss:     0.0252 Validation Accuracy: 0.941333\n",
      "Epoch  1, CIFAR-10 Batch 218:  Loss:     0.0239 Validation Accuracy: 0.939333\n",
      "Epoch  1, CIFAR-10 Batch 219:  Loss:     0.0274 Validation Accuracy: 0.938000\n",
      "Epoch  1, CIFAR-10 Batch 220:  Loss:     0.0242 Validation Accuracy: 0.942000\n",
      "Epoch  1, CIFAR-10 Batch 221:  Loss:     0.0171 Validation Accuracy: 0.942667\n",
      "Epoch  1, CIFAR-10 Batch 222:  Loss:     0.0259 Validation Accuracy: 0.939333\n",
      "Epoch  1, CIFAR-10 Batch 223:  Loss:     0.0265 Validation Accuracy: 0.946667\n",
      "Epoch  1, CIFAR-10 Batch 224:  Loss:     0.0226 Validation Accuracy: 0.950667\n",
      "Epoch  1, CIFAR-10 Batch 225:  Loss:     0.0220 Validation Accuracy: 0.948000\n",
      "Epoch  1, CIFAR-10 Batch 226:  Loss:     0.0223 Validation Accuracy: 0.949333\n",
      "Epoch  1, CIFAR-10 Batch 227:  Loss:     0.0224 Validation Accuracy: 0.948000\n",
      "Epoch  1, CIFAR-10 Batch 228:  Loss:     0.0267 Validation Accuracy: 0.936000\n",
      "Epoch  1, CIFAR-10 Batch 229:  Loss:     0.0232 Validation Accuracy: 0.943333\n",
      "Epoch  1, CIFAR-10 Batch 230:  Loss:     0.0229 Validation Accuracy: 0.942667\n",
      "Epoch  1, CIFAR-10 Batch 231:  Loss:     0.0239 Validation Accuracy: 0.936667\n",
      "Epoch  1, CIFAR-10 Batch 232:  Loss:     0.0213 Validation Accuracy: 0.944667\n",
      "Epoch  1, CIFAR-10 Batch 233:  Loss:     0.0209 Validation Accuracy: 0.952000\n",
      "Epoch  1, CIFAR-10 Batch 234:  Loss:     0.0215 Validation Accuracy: 0.949333\n",
      "Epoch  1, CIFAR-10 Batch 235:  Loss:     0.0218 Validation Accuracy: 0.945333\n",
      "Epoch  1, CIFAR-10 Batch 236:  Loss:     0.0215 Validation Accuracy: 0.944000\n",
      "Epoch  1, CIFAR-10 Batch 237:  Loss:     0.0259 Validation Accuracy: 0.945333\n",
      "Epoch  1, CIFAR-10 Batch 238:  Loss:     0.0213 Validation Accuracy: 0.940000\n",
      "Epoch  1, CIFAR-10 Batch 239:  Loss:     0.0227 Validation Accuracy: 0.943333\n",
      "Epoch  1, CIFAR-10 Batch 240:  Loss:     0.0247 Validation Accuracy: 0.948667\n",
      "Epoch  1, CIFAR-10 Batch 241:  Loss:     0.0217 Validation Accuracy: 0.947333\n",
      "Epoch  1, CIFAR-10 Batch 242:  Loss:     0.0191 Validation Accuracy: 0.945333\n",
      "Epoch  1, CIFAR-10 Batch 243:  Loss:     0.0229 Validation Accuracy: 0.943333\n",
      "Epoch  1, CIFAR-10 Batch 244:  Loss:     0.0216 Validation Accuracy: 0.945333\n",
      "Epoch  1, CIFAR-10 Batch 245:  Loss:     0.0224 Validation Accuracy: 0.944000\n",
      "Epoch  1, CIFAR-10 Batch 246:  Loss:     0.0227 Validation Accuracy: 0.944667\n",
      "Epoch  1, CIFAR-10 Batch 247:  Loss:     0.0240 Validation Accuracy: 0.950000\n",
      "Epoch  1, CIFAR-10 Batch 248:  Loss:     0.0212 Validation Accuracy: 0.941333\n",
      "Epoch  1, CIFAR-10 Batch 249:  Loss:     0.0222 Validation Accuracy: 0.942000\n",
      "Epoch  1, CIFAR-10 Batch 250:  Loss:     0.0218 Validation Accuracy: 0.947333\n",
      "Epoch  1, CIFAR-10 Batch 251:  Loss:     0.0205 Validation Accuracy: 0.941333\n",
      "Epoch  1, CIFAR-10 Batch 252:  Loss:     0.0219 Validation Accuracy: 0.946000\n",
      "Epoch  1, CIFAR-10 Batch 253:  Loss:     0.0207 Validation Accuracy: 0.944000\n",
      "Epoch  1, CIFAR-10 Batch 254:  Loss:     0.0256 Validation Accuracy: 0.938667\n",
      "Epoch  1, CIFAR-10 Batch 255:  Loss:     0.0206 Validation Accuracy: 0.946667\n",
      "Epoch  1, CIFAR-10 Batch 256:  Loss:     0.0228 Validation Accuracy: 0.938667\n",
      "Epoch  1, CIFAR-10 Batch 257:  Loss:     0.0199 Validation Accuracy: 0.943333\n",
      "Epoch  1, CIFAR-10 Batch 258:  Loss:     0.0225 Validation Accuracy: 0.945333\n",
      "Epoch  1, CIFAR-10 Batch 259:  Loss:     0.0231 Validation Accuracy: 0.945333\n",
      "Epoch  1, CIFAR-10 Batch 260:  Loss:     0.0192 Validation Accuracy: 0.943333\n",
      "Epoch  1, CIFAR-10 Batch 261:  Loss:     0.0244 Validation Accuracy: 0.947333\n",
      "Epoch  1, CIFAR-10 Batch 262:  Loss:     0.0200 Validation Accuracy: 0.949333\n",
      "Epoch  1, CIFAR-10 Batch 263:  Loss:     0.0193 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 264:  Loss:     0.0191 Validation Accuracy: 0.953333\n",
      "Epoch  1, CIFAR-10 Batch 265:  Loss:     0.0222 Validation Accuracy: 0.944000\n",
      "Epoch  1, CIFAR-10 Batch 266:  Loss:     0.0200 Validation Accuracy: 0.940000\n",
      "Epoch  1, CIFAR-10 Batch 267:  Loss:     0.0214 Validation Accuracy: 0.946667\n",
      "Epoch  1, CIFAR-10 Batch 268:  Loss:     0.0221 Validation Accuracy: 0.946000\n",
      "Epoch  1, CIFAR-10 Batch 269:  Loss:     0.0190 Validation Accuracy: 0.950000\n",
      "Epoch  1, CIFAR-10 Batch 270:  Loss:     0.0195 Validation Accuracy: 0.952000\n",
      "Epoch  1, CIFAR-10 Batch 271:  Loss:     0.0214 Validation Accuracy: 0.946000\n",
      "Epoch  1, CIFAR-10 Batch 272:  Loss:     0.0217 Validation Accuracy: 0.950000\n",
      "Epoch  1, CIFAR-10 Batch 273:  Loss:     0.0212 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 274:  Loss:     0.0197 Validation Accuracy: 0.948000\n",
      "Epoch  1, CIFAR-10 Batch 275:  Loss:     0.0208 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 276:  Loss:     0.0191 Validation Accuracy: 0.946667\n",
      "Epoch  1, CIFAR-10 Batch 277:  Loss:     0.0220 Validation Accuracy: 0.945333\n",
      "Epoch  1, CIFAR-10 Batch 278:  Loss:     0.0185 Validation Accuracy: 0.946667\n",
      "Epoch  1, CIFAR-10 Batch 279:  Loss:     0.0242 Validation Accuracy: 0.944667\n",
      "Epoch  1, CIFAR-10 Batch 280:  Loss:     0.0191 Validation Accuracy: 0.949333\n",
      "Epoch  1, CIFAR-10 Batch 281:  Loss:     0.0211 Validation Accuracy: 0.949333\n",
      "Epoch  1, CIFAR-10 Batch 282:  Loss:     0.0205 Validation Accuracy: 0.951333\n",
      "Epoch  1, CIFAR-10 Batch 283:  Loss:     0.0200 Validation Accuracy: 0.950667\n",
      "Epoch  1, CIFAR-10 Batch 284:  Loss:     0.0169 Validation Accuracy: 0.951333\n",
      "Epoch  1, CIFAR-10 Batch 285:  Loss:     0.0195 Validation Accuracy: 0.940667\n",
      "Epoch  1, CIFAR-10 Batch 286:  Loss:     0.0222 Validation Accuracy: 0.948000\n",
      "Epoch  1, CIFAR-10 Batch 287:  Loss:     0.0237 Validation Accuracy: 0.944667\n",
      "Epoch  1, CIFAR-10 Batch 288:  Loss:     0.0187 Validation Accuracy: 0.943333\n",
      "Epoch  1, CIFAR-10 Batch 289:  Loss:     0.0219 Validation Accuracy: 0.944667\n",
      "Epoch  1, CIFAR-10 Batch 290:  Loss:     0.0176 Validation Accuracy: 0.945333\n",
      "Epoch  1, CIFAR-10 Batch 291:  Loss:     0.0181 Validation Accuracy: 0.945333\n",
      "Epoch  1, CIFAR-10 Batch 292:  Loss:     0.0183 Validation Accuracy: 0.951333\n",
      "Epoch  1, CIFAR-10 Batch 293:  Loss:     0.0210 Validation Accuracy: 0.948000\n",
      "Epoch  1, CIFAR-10 Batch 294:  Loss:     0.0192 Validation Accuracy: 0.946667\n",
      "Epoch  1, CIFAR-10 Batch 295:  Loss:     0.0242 Validation Accuracy: 0.944667\n",
      "Epoch  1, CIFAR-10 Batch 296:  Loss:     0.0182 Validation Accuracy: 0.940000\n",
      "Epoch  1, CIFAR-10 Batch 297:  Loss:     0.0194 Validation Accuracy: 0.953333\n",
      "Epoch  1, CIFAR-10 Batch 298:  Loss:     0.0193 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 299:  Loss:     0.0202 Validation Accuracy: 0.951333\n",
      "Epoch  1, CIFAR-10 Batch 300:  Loss:     0.0198 Validation Accuracy: 0.948000\n",
      "Epoch  1, CIFAR-10 Batch 301:  Loss:     0.0196 Validation Accuracy: 0.950000\n",
      "Epoch  1, CIFAR-10 Batch 302:  Loss:     0.0188 Validation Accuracy: 0.950667\n",
      "Epoch  1, CIFAR-10 Batch 303:  Loss:     0.0202 Validation Accuracy: 0.945333\n",
      "Epoch  1, CIFAR-10 Batch 304:  Loss:     0.0191 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 305:  Loss:     0.0199 Validation Accuracy: 0.954667\n",
      "Epoch  1, CIFAR-10 Batch 306:  Loss:     0.0200 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 307:  Loss:     0.0232 Validation Accuracy: 0.950667\n",
      "Epoch  1, CIFAR-10 Batch 308:  Loss:     0.0214 Validation Accuracy: 0.950000\n",
      "Epoch  1, CIFAR-10 Batch 309:  Loss:     0.0180 Validation Accuracy: 0.952000\n",
      "Epoch  1, CIFAR-10 Batch 310:  Loss:     0.0207 Validation Accuracy: 0.952000\n",
      "Epoch  1, CIFAR-10 Batch 311:  Loss:     0.0205 Validation Accuracy: 0.948667\n",
      "Epoch  1, CIFAR-10 Batch 312:  Loss:     0.0205 Validation Accuracy: 0.947333\n",
      "Epoch  1, CIFAR-10 Batch 313:  Loss:     0.0191 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 314:  Loss:     0.0209 Validation Accuracy: 0.953333\n",
      "Epoch  1, CIFAR-10 Batch 315:  Loss:     0.0183 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 316:  Loss:     0.0212 Validation Accuracy: 0.953333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, CIFAR-10 Batch 317:  Loss:     0.0210 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 318:  Loss:     0.0186 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 319:  Loss:     0.0266 Validation Accuracy: 0.954000\n",
      "Epoch  1, CIFAR-10 Batch 320:  Loss:     0.0223 Validation Accuracy: 0.953333\n",
      "Epoch  1, CIFAR-10 Batch 321:  Loss:     0.0248 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 322:  Loss:     0.0198 Validation Accuracy: 0.950000\n",
      "Epoch  1, CIFAR-10 Batch 323:  Loss:     0.0225 Validation Accuracy: 0.950667\n",
      "Epoch  1, CIFAR-10 Batch 324:  Loss:     0.0238 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 325:  Loss:     0.0179 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 326:  Loss:     0.0204 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 327:  Loss:     0.0173 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 328:  Loss:     0.0215 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 329:  Loss:     0.0214 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 330:  Loss:     0.0206 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 331:  Loss:     0.0185 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 332:  Loss:     0.0167 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 333:  Loss:     0.0200 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 334:  Loss:     0.0194 Validation Accuracy: 0.954667\n",
      "Epoch  1, CIFAR-10 Batch 335:  Loss:     0.0218 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 336:  Loss:     0.0186 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 337:  Loss:     0.0177 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 338:  Loss:     0.0194 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 339:  Loss:     0.0197 Validation Accuracy: 0.950667\n",
      "Epoch  1, CIFAR-10 Batch 340:  Loss:     0.0180 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 341:  Loss:     0.0194 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 342:  Loss:     0.0219 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 343:  Loss:     0.0182 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 344:  Loss:     0.0195 Validation Accuracy: 0.953333\n",
      "Epoch  1, CIFAR-10 Batch 345:  Loss:     0.0153 Validation Accuracy: 0.953333\n",
      "Epoch  1, CIFAR-10 Batch 346:  Loss:     0.0208 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 347:  Loss:     0.0172 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 348:  Loss:     0.0175 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 349:  Loss:     0.0202 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 350:  Loss:     0.0162 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 351:  Loss:     0.0178 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 352:  Loss:     0.0172 Validation Accuracy: 0.954000\n",
      "Epoch  1, CIFAR-10 Batch 353:  Loss:     0.0194 Validation Accuracy: 0.950000\n",
      "Epoch  1, CIFAR-10 Batch 354:  Loss:     0.0191 Validation Accuracy: 0.957333\n",
      "Epoch  1, CIFAR-10 Batch 355:  Loss:     0.0189 Validation Accuracy: 0.950000\n",
      "Epoch  1, CIFAR-10 Batch 356:  Loss:     0.0210 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 357:  Loss:     0.0198 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 358:  Loss:     0.0203 Validation Accuracy: 0.952000\n",
      "Epoch  1, CIFAR-10 Batch 359:  Loss:     0.0207 Validation Accuracy: 0.952000\n",
      "Epoch  1, CIFAR-10 Batch 360:  Loss:     0.0183 Validation Accuracy: 0.953333\n",
      "Epoch  1, CIFAR-10 Batch 361:  Loss:     0.0163 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 362:  Loss:     0.0173 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 363:  Loss:     0.0206 Validation Accuracy: 0.954667\n",
      "Epoch  1, CIFAR-10 Batch 364:  Loss:     0.0160 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 365:  Loss:     0.0173 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 366:  Loss:     0.0172 Validation Accuracy: 0.954667\n",
      "Epoch  1, CIFAR-10 Batch 367:  Loss:     0.0193 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 368:  Loss:     0.0178 Validation Accuracy: 0.954667\n",
      "Epoch  1, CIFAR-10 Batch 369:  Loss:     0.0215 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 370:  Loss:     0.0146 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 371:  Loss:     0.0176 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 372:  Loss:     0.0195 Validation Accuracy: 0.954667\n",
      "Epoch  1, CIFAR-10 Batch 373:  Loss:     0.0177 Validation Accuracy: 0.950667\n",
      "Epoch  1, CIFAR-10 Batch 374:  Loss:     0.0153 Validation Accuracy: 0.948000\n",
      "Epoch  1, CIFAR-10 Batch 375:  Loss:     0.0179 Validation Accuracy: 0.954667\n",
      "Epoch  1, CIFAR-10 Batch 376:  Loss:     0.0191 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 377:  Loss:     0.0195 Validation Accuracy: 0.952000\n",
      "Epoch  1, CIFAR-10 Batch 378:  Loss:     0.0190 Validation Accuracy: 0.954667\n",
      "Epoch  1, CIFAR-10 Batch 379:  Loss:     0.0186 Validation Accuracy: 0.953333\n",
      "Epoch  1, CIFAR-10 Batch 380:  Loss:     0.0190 Validation Accuracy: 0.954000\n",
      "Epoch  1, CIFAR-10 Batch 381:  Loss:     0.0191 Validation Accuracy: 0.954000\n",
      "Epoch  1, CIFAR-10 Batch 382:  Loss:     0.0163 Validation Accuracy: 0.957333\n",
      "Epoch  1, CIFAR-10 Batch 383:  Loss:     0.0185 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 384:  Loss:     0.0151 Validation Accuracy: 0.954000\n",
      "Epoch  1, CIFAR-10 Batch 385:  Loss:     0.0181 Validation Accuracy: 0.954000\n",
      "Epoch  1, CIFAR-10 Batch 386:  Loss:     0.0195 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 387:  Loss:     0.0198 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 388:  Loss:     0.0198 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 389:  Loss:     0.0167 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 390:  Loss:     0.0167 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 391:  Loss:     0.0165 Validation Accuracy: 0.953333\n",
      "Epoch  1, CIFAR-10 Batch 392:  Loss:     0.0188 Validation Accuracy: 0.954000\n",
      "Epoch  1, CIFAR-10 Batch 393:  Loss:     0.0194 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 394:  Loss:     0.0212 Validation Accuracy: 0.954000\n",
      "Epoch  1, CIFAR-10 Batch 395:  Loss:     0.0209 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 396:  Loss:     0.0200 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 397:  Loss:     0.0184 Validation Accuracy: 0.957333\n",
      "Epoch  1, CIFAR-10 Batch 398:  Loss:     0.0155 Validation Accuracy: 0.953333\n",
      "Epoch  1, CIFAR-10 Batch 399:  Loss:     0.0208 Validation Accuracy: 0.950667\n",
      "Epoch  1, CIFAR-10 Batch 400:  Loss:     0.0197 Validation Accuracy: 0.948667\n",
      "Epoch  1, CIFAR-10 Batch 401:  Loss:     0.0162 Validation Accuracy: 0.953333\n",
      "Epoch  1, CIFAR-10 Batch 402:  Loss:     0.0214 Validation Accuracy: 0.954667\n",
      "Epoch  1, CIFAR-10 Batch 403:  Loss:     0.0165 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 404:  Loss:     0.0195 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 405:  Loss:     0.0192 Validation Accuracy: 0.951333\n",
      "Epoch  1, CIFAR-10 Batch 406:  Loss:     0.0170 Validation Accuracy: 0.949333\n",
      "Epoch  1, CIFAR-10 Batch 407:  Loss:     0.0163 Validation Accuracy: 0.952000\n",
      "Epoch  1, CIFAR-10 Batch 408:  Loss:     0.0197 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 409:  Loss:     0.0218 Validation Accuracy: 0.954667\n",
      "Epoch  1, CIFAR-10 Batch 410:  Loss:     0.0183 Validation Accuracy: 0.954000\n",
      "Epoch  1, CIFAR-10 Batch 411:  Loss:     0.0191 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 412:  Loss:     0.0173 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 413:  Loss:     0.0196 Validation Accuracy: 0.948000\n",
      "Epoch  1, CIFAR-10 Batch 414:  Loss:     0.0195 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 415:  Loss:     0.0208 Validation Accuracy: 0.946667\n",
      "Epoch  1, CIFAR-10 Batch 416:  Loss:     0.0179 Validation Accuracy: 0.946000\n",
      "Epoch  1, CIFAR-10 Batch 417:  Loss:     0.0161 Validation Accuracy: 0.954667\n",
      "Epoch  1, CIFAR-10 Batch 418:  Loss:     0.0227 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 419:  Loss:     0.0224 Validation Accuracy: 0.957333\n",
      "Epoch  1, CIFAR-10 Batch 420:  Loss:     0.0179 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 421:  Loss:     0.0197 Validation Accuracy: 0.962000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, CIFAR-10 Batch 422:  Loss:     0.0190 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 423:  Loss:     0.0194 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 424:  Loss:     0.0177 Validation Accuracy: 0.954000\n",
      "Epoch  1, CIFAR-10 Batch 425:  Loss:     0.0166 Validation Accuracy: 0.950000\n",
      "Epoch  1, CIFAR-10 Batch 426:  Loss:     0.0168 Validation Accuracy: 0.954667\n",
      "Epoch  1, CIFAR-10 Batch 427:  Loss:     0.0195 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 428:  Loss:     0.0165 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 429:  Loss:     0.0180 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 430:  Loss:     0.0188 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 431:  Loss:     0.0188 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 432:  Loss:     0.0199 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 433:  Loss:     0.0181 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 434:  Loss:     0.0145 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 435:  Loss:     0.0195 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 436:  Loss:     0.0160 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 437:  Loss:     0.0175 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 438:  Loss:     0.0191 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 439:  Loss:     0.0211 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 440:  Loss:     0.0173 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 441:  Loss:     0.0170 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 442:  Loss:     0.0174 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 443:  Loss:     0.0167 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 444:  Loss:     0.0163 Validation Accuracy: 0.954000\n",
      "Epoch  1, CIFAR-10 Batch 445:  Loss:     0.0168 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 446:  Loss:     0.0171 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 447:  Loss:     0.0187 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 448:  Loss:     0.0174 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 449:  Loss:     0.0154 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 450:  Loss:     0.0141 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 451:  Loss:     0.0193 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 452:  Loss:     0.0169 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 453:  Loss:     0.0181 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 454:  Loss:     0.0178 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 455:  Loss:     0.0197 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 456:  Loss:     0.0174 Validation Accuracy: 0.957333\n",
      "Epoch  1, CIFAR-10 Batch 457:  Loss:     0.0144 Validation Accuracy: 0.953333\n",
      "Epoch  1, CIFAR-10 Batch 458:  Loss:     0.0176 Validation Accuracy: 0.954667\n",
      "Epoch  1, CIFAR-10 Batch 459:  Loss:     0.0179 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 460:  Loss:     0.0162 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 461:  Loss:     0.0186 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 462:  Loss:     0.0168 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 463:  Loss:     0.0190 Validation Accuracy: 0.957333\n",
      "Epoch  1, CIFAR-10 Batch 464:  Loss:     0.0152 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 465:  Loss:     0.0160 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 466:  Loss:     0.0173 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 467:  Loss:     0.0162 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 468:  Loss:     0.0166 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 469:  Loss:     0.0152 Validation Accuracy: 0.965333\n",
      "Epoch  1, CIFAR-10 Batch 470:  Loss:     0.0157 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 471:  Loss:     0.0189 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 472:  Loss:     0.0152 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 473:  Loss:     0.0174 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 474:  Loss:     0.0184 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 475:  Loss:     0.0169 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 476:  Loss:     0.0175 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 477:  Loss:     0.0156 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 478:  Loss:     0.0163 Validation Accuracy: 0.965333\n",
      "Epoch  1, CIFAR-10 Batch 479:  Loss:     0.0153 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 480:  Loss:     0.0157 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 481:  Loss:     0.0159 Validation Accuracy: 0.965333\n",
      "Epoch  1, CIFAR-10 Batch 482:  Loss:     0.0154 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 483:  Loss:     0.0173 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 484:  Loss:     0.0162 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 485:  Loss:     0.0174 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 486:  Loss:     0.0171 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 487:  Loss:     0.0120 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 488:  Loss:     0.0164 Validation Accuracy: 0.965333\n",
      "Epoch  1, CIFAR-10 Batch 489:  Loss:     0.0169 Validation Accuracy: 0.965333\n",
      "Epoch  1, CIFAR-10 Batch 490:  Loss:     0.0169 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 491:  Loss:     0.0164 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 492:  Loss:     0.0145 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 493:  Loss:     0.0160 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 494:  Loss:     0.0151 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 495:  Loss:     0.0155 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 496:  Loss:     0.0149 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 497:  Loss:     0.0162 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 498:  Loss:     0.0125 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 499:  Loss:     0.0151 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 500:  Loss:     0.0194 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 501:  Loss:     0.0144 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 502:  Loss:     0.0171 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 503:  Loss:     0.0154 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 504:  Loss:     0.0160 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 505:  Loss:     0.0170 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 506:  Loss:     0.0180 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 507:  Loss:     0.0177 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 508:  Loss:     0.0176 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 509:  Loss:     0.0155 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 510:  Loss:     0.0163 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 511:  Loss:     0.0149 Validation Accuracy: 0.966667\n",
      "Epoch  1, CIFAR-10 Batch 512:  Loss:     0.0171 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 513:  Loss:     0.0158 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 514:  Loss:     0.0168 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 515:  Loss:     0.0142 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 516:  Loss:     0.0174 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 517:  Loss:     0.0160 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 518:  Loss:     0.0154 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 519:  Loss:     0.0173 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 520:  Loss:     0.0199 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 521:  Loss:     0.0177 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 522:  Loss:     0.0178 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 523:  Loss:     0.0150 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 524:  Loss:     0.0186 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 525:  Loss:     0.0196 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 526:  Loss:     0.0155 Validation Accuracy: 0.964000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, CIFAR-10 Batch 527:  Loss:     0.0154 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 528:  Loss:     0.0148 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 529:  Loss:     0.0179 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 530:  Loss:     0.0180 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 531:  Loss:     0.0151 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 532:  Loss:     0.0150 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 533:  Loss:     0.0144 Validation Accuracy: 0.967333\n",
      "Epoch  1, CIFAR-10 Batch 534:  Loss:     0.0148 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 535:  Loss:     0.0170 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 536:  Loss:     0.0174 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 537:  Loss:     0.0124 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 538:  Loss:     0.0167 Validation Accuracy: 0.967333\n",
      "Epoch  1, CIFAR-10 Batch 539:  Loss:     0.0136 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 540:  Loss:     0.0183 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 541:  Loss:     0.0158 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 542:  Loss:     0.0185 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 543:  Loss:     0.0143 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 544:  Loss:     0.0149 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 545:  Loss:     0.0192 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 546:  Loss:     0.0160 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 547:  Loss:     0.0185 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 548:  Loss:     0.0164 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 549:  Loss:     0.0158 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 550:  Loss:     0.0152 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 551:  Loss:     0.0167 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 552:  Loss:     0.0168 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 553:  Loss:     0.0176 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 554:  Loss:     0.0146 Validation Accuracy: 0.966667\n",
      "Epoch  1, CIFAR-10 Batch 555:  Loss:     0.0162 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 556:  Loss:     0.0172 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 557:  Loss:     0.0147 Validation Accuracy: 0.965333\n",
      "Epoch  1, CIFAR-10 Batch 558:  Loss:     0.0132 Validation Accuracy: 0.966667\n",
      "Epoch  1, CIFAR-10 Batch 559:  Loss:     0.0143 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 560:  Loss:     0.0171 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 561:  Loss:     0.0155 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 562:  Loss:     0.0156 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 563:  Loss:     0.0157 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 564:  Loss:     0.0206 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 565:  Loss:     0.0138 Validation Accuracy: 0.965333\n",
      "Epoch  1, CIFAR-10 Batch 566:  Loss:     0.0156 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 567:  Loss:     0.0154 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 568:  Loss:     0.0190 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 569:  Loss:     0.0134 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 570:  Loss:     0.0126 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 571:  Loss:     0.0144 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 572:  Loss:     0.0190 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 573:  Loss:     0.0147 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 574:  Loss:     0.0154 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 575:  Loss:     0.0154 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 576:  Loss:     0.0143 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 577:  Loss:     0.0174 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 578:  Loss:     0.0194 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 579:  Loss:     0.0144 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 580:  Loss:     0.0161 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 581:  Loss:     0.0179 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 582:  Loss:     0.0169 Validation Accuracy: 0.966667\n",
      "Epoch  1, CIFAR-10 Batch 583:  Loss:     0.0151 Validation Accuracy: 0.967333\n",
      "Epoch  1, CIFAR-10 Batch 584:  Loss:     0.0151 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 585:  Loss:     0.0167 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 586:  Loss:     0.0177 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 587:  Loss:     0.0181 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 588:  Loss:     0.0172 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 589:  Loss:     0.0128 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 590:  Loss:     0.0136 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 591:  Loss:     0.0142 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 592:  Loss:     0.0202 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 593:  Loss:     0.0155 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 594:  Loss:     0.0138 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 595:  Loss:     0.0176 Validation Accuracy: 0.957333\n",
      "Epoch  1, CIFAR-10 Batch 596:  Loss:     0.0146 Validation Accuracy: 0.965333\n",
      "Epoch  1, CIFAR-10 Batch 597:  Loss:     0.0161 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 598:  Loss:     0.0177 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 599:  Loss:     0.0148 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 600:  Loss:     0.0162 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 601:  Loss:     0.0157 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 602:  Loss:     0.0163 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 603:  Loss:     0.0171 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 604:  Loss:     0.0130 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 605:  Loss:     0.0145 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 606:  Loss:     0.0165 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 607:  Loss:     0.0160 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 608:  Loss:     0.0149 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 609:  Loss:     0.0176 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 610:  Loss:     0.0171 Validation Accuracy: 0.967333\n",
      "Epoch  1, CIFAR-10 Batch 611:  Loss:     0.0148 Validation Accuracy: 0.967333\n",
      "Epoch  1, CIFAR-10 Batch 612:  Loss:     0.0169 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 613:  Loss:     0.0189 Validation Accuracy: 0.965333\n",
      "Epoch  1, CIFAR-10 Batch 614:  Loss:     0.0160 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 615:  Loss:     0.0159 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 616:  Loss:     0.0142 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 617:  Loss:     0.0166 Validation Accuracy: 0.957333\n",
      "Epoch  1, CIFAR-10 Batch 618:  Loss:     0.0155 Validation Accuracy: 0.956667\n",
      "Epoch  1, CIFAR-10 Batch 619:  Loss:     0.0134 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 620:  Loss:     0.0200 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 621:  Loss:     0.0175 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 622:  Loss:     0.0150 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 623:  Loss:     0.0170 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 624:  Loss:     0.0161 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 625:  Loss:     0.0163 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 626:  Loss:     0.0156 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 627:  Loss:     0.0163 Validation Accuracy: 0.967333\n",
      "Epoch  1, CIFAR-10 Batch 628:  Loss:     0.0153 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 629:  Loss:     0.0173 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 630:  Loss:     0.0161 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 631:  Loss:     0.0189 Validation Accuracy: 0.959333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, CIFAR-10 Batch 632:  Loss:     0.0146 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 633:  Loss:     0.0141 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 634:  Loss:     0.0128 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 635:  Loss:     0.0190 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 636:  Loss:     0.0146 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 637:  Loss:     0.0171 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 638:  Loss:     0.0166 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 639:  Loss:     0.0182 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 640:  Loss:     0.0181 Validation Accuracy: 0.952667\n",
      "Epoch  1, CIFAR-10 Batch 641:  Loss:     0.0177 Validation Accuracy: 0.955333\n",
      "Epoch  1, CIFAR-10 Batch 642:  Loss:     0.0152 Validation Accuracy: 0.948000\n",
      "Epoch  1, CIFAR-10 Batch 643:  Loss:     0.0180 Validation Accuracy: 0.952000\n",
      "Epoch  1, CIFAR-10 Batch 644:  Loss:     0.0155 Validation Accuracy: 0.957333\n",
      "Epoch  1, CIFAR-10 Batch 645:  Loss:     0.0154 Validation Accuracy: 0.950667\n",
      "Epoch  1, CIFAR-10 Batch 646:  Loss:     0.0181 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 647:  Loss:     0.0158 Validation Accuracy: 0.965333\n",
      "Epoch  1, CIFAR-10 Batch 648:  Loss:     0.0143 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 649:  Loss:     0.0159 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 650:  Loss:     0.0158 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 651:  Loss:     0.0155 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 652:  Loss:     0.0128 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 653:  Loss:     0.0157 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 654:  Loss:     0.0154 Validation Accuracy: 0.962667\n",
      "Epoch  1, CIFAR-10 Batch 655:  Loss:     0.0182 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 656:  Loss:     0.0197 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 657:  Loss:     0.0159 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 658:  Loss:     0.0168 Validation Accuracy: 0.957333\n",
      "Epoch  1, CIFAR-10 Batch 659:  Loss:     0.0176 Validation Accuracy: 0.956000\n",
      "Epoch  1, CIFAR-10 Batch 660:  Loss:     0.0128 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 661:  Loss:     0.0140 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 662:  Loss:     0.0162 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 663:  Loss:     0.0199 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 664:  Loss:     0.0182 Validation Accuracy: 0.958000\n",
      "Epoch  1, CIFAR-10 Batch 665:  Loss:     0.0152 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 666:  Loss:     0.0194 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 667:  Loss:     0.0188 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 668:  Loss:     0.0156 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 669:  Loss:     0.0145 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 670:  Loss:     0.0132 Validation Accuracy: 0.964000\n",
      "Epoch  1, CIFAR-10 Batch 671:  Loss:     0.0155 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 672:  Loss:     0.0150 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 673:  Loss:     0.0164 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 674:  Loss:     0.0147 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 675:  Loss:     0.0179 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 676:  Loss:     0.0192 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 677:  Loss:     0.0154 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 678:  Loss:     0.0151 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 679:  Loss:     0.0158 Validation Accuracy: 0.965333\n",
      "Epoch  1, CIFAR-10 Batch 680:  Loss:     0.0127 Validation Accuracy: 0.965333\n",
      "Epoch  1, CIFAR-10 Batch 681:  Loss:     0.0188 Validation Accuracy: 0.969333\n",
      "Epoch  1, CIFAR-10 Batch 682:  Loss:     0.0129 Validation Accuracy: 0.968667\n",
      "Epoch  1, CIFAR-10 Batch 683:  Loss:     0.0137 Validation Accuracy: 0.968000\n",
      "Epoch  1, CIFAR-10 Batch 684:  Loss:     0.0165 Validation Accuracy: 0.968000\n",
      "Epoch  1, CIFAR-10 Batch 685:  Loss:     0.0147 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 686:  Loss:     0.0139 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 687:  Loss:     0.0150 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 688:  Loss:     0.0149 Validation Accuracy: 0.963333\n",
      "Epoch  1, CIFAR-10 Batch 689:  Loss:     0.0170 Validation Accuracy: 0.967333\n",
      "Epoch  1, CIFAR-10 Batch 690:  Loss:     0.0142 Validation Accuracy: 0.966000\n",
      "Epoch  1, CIFAR-10 Batch 691:  Loss:     0.0139 Validation Accuracy: 0.964667\n",
      "Epoch  1, CIFAR-10 Batch 692:  Loss:     0.0147 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 693:  Loss:     0.0149 Validation Accuracy: 0.960667\n",
      "Epoch  1, CIFAR-10 Batch 694:  Loss:     0.0123 Validation Accuracy: 0.961333\n",
      "Epoch  1, CIFAR-10 Batch 695:  Loss:     0.0166 Validation Accuracy: 0.958667\n",
      "Epoch  1, CIFAR-10 Batch 696:  Loss:     0.0151 Validation Accuracy: 0.959333\n",
      "Epoch  1, CIFAR-10 Batch 697:  Loss:     0.0143 Validation Accuracy: 0.960000\n",
      "Epoch  1, CIFAR-10 Batch 698:  Loss:     0.0148 Validation Accuracy: 0.962000\n",
      "Epoch  1, CIFAR-10 Batch 699:  Loss:     0.0145 Validation Accuracy: 0.961333\n"
     ]
    }
   ],
   "source": [
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = batch_max\n",
    "        for batch_i in range(1, n_batches):\n",
    "            batch_features, batch_labels = pickle.load(open('data/batch' + str(batch_i), mode='rb'))\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            if(print_stats(sess, batch_features, batch_labels, cost, accuracy) > break_percent):\n",
    "                break\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
